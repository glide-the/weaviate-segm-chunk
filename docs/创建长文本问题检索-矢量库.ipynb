{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef3623e-c637-4d25-95e1-31f1b3a2f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U weaviate-client pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faf4b3b9-cd5f-429e-8feb-e9ce44412d16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# import weaviate\n",
    "# from weaviate.classes.init import Auth \n",
    "\n",
    "# # Best practice: store your credentials in environment variables\n",
    "# weaviate_url = 'https://dbvzpt0resxqjgufx5ing.c0.us-west3.gcp.weaviate.cloud'\n",
    "# weaviate_api_key = ''\n",
    "\n",
    "# # Connect to Weaviate Cloud\n",
    "# client = weaviate.connect_to_weaviate_cloud(\n",
    "#     cluster_url=weaviate_url, \n",
    "#     auth_credentials=Auth.api_key(weaviate_api_key),\n",
    "# )\n",
    "\n",
    "# print(client.is_ready()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a41e0ae-580a-4ffe-afd6-bc680d4eb759",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ceph/develop/jiawei/weaviate-python-client/weaviate/warnings.py:133: DeprecationWarning: Dep005: You are using weaviate-client version 0.1.dev3117+gae1bb03. The latest version is 4.10.2.\n",
      "            Consider upgrading to the latest version. See https://weaviate.io/developers/weaviate/client-libraries/python for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    " \n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "print(client.is_ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee49eb23-9b37-4a69-b5e9-236b036a7f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.collections.delete(\"OpenVidLateContext_jina_v2_zh\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa41ea09-aaa4-4a7f-af64-fbfbe3d453ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weaviate.collections.collection.sync.Collection at 0x7fd8e07b9a80>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from weaviate.classes.config import Configure, Property, DataType, VectorDistances\n",
    " \n",
    "import weaviate.classes as wvc\n",
    "import weaviate.classes.config as wvcc\n",
    "client.collections.create(\n",
    "    \"OpenVidLateContext_jina_v2_zh\",\n",
    "    \n",
    "    vectorizer_config=wvc.config.Configure.Vectorizer.none(),\n",
    "  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fba8442-e3c3-47f2-b492-c73899cb9b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已存在，无需下载。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "import os\n",
    "import requests\n",
    "\n",
    "file_path = \"OpenVid-1M.csv\"\n",
    "\n",
    "# 检查文件是否存在，如果不存在则下载\n",
    "if not os.path.exists(file_path):\n",
    "    print(\"文件不存在，正在下载...\")\n",
    "    response = requests.get(\n",
    "        \"https://huggingface.co/datasets/nkp37/OpenVid-1M/resolve/main/data/train/OpenVid-1M.csv\"\n",
    "    )\n",
    "    # 保存文件\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(\"文件下载完成！\")\n",
    "else:\n",
    "    print(\"文件已存在，无需下载。\")\n",
    "\n",
    "# 确认文件状态\n",
    "file_exists = os.path.exists(file_path)\n",
    "file_exists\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd802924-2db0-4c97-bea2-e8e6242ab08d",
   "metadata": {},
   "source": [
    "### 操作方式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485552d0-0430-4e04-929f-2f16e2b6abd0",
   "metadata": {},
   "source": [
    "以下是将文本分块为句子的一些通用函数，以及后期分块背后的大部分操作。\n",
    "\n",
    "后期分块与我们在简单分块的文本上看到的块完全相同，但块嵌入取自标记嵌入的池化，而不是独立嵌入的块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "904b7d9a-557f-4290-bd8e-0b696bac1168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_by_sentences(input_text: str, tokenizer: callable, mark_text: str='.'):\n",
    "    \"\"\"\n",
    "    Split the input text into sentences using the tokenizer\n",
    "    :param input_text: The text snippet to split into sentences\n",
    "    :param tokenizer: The tokenizer to use\n",
    "    :return: A tuple containing the list of text chunks and their corresponding token spans\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(input_text, return_tensors='pt', return_offsets_mapping=True)\n",
    "    punctuation_mark_id = tokenizer.convert_tokens_to_ids(mark_text)\n",
    "    sep_id = tokenizer.convert_tokens_to_ids('[SEP]')\n",
    "    token_offsets = inputs['offset_mapping'][0]\n",
    "    token_ids = inputs['input_ids'][0]\n",
    "    chunk_positions = [\n",
    "        (i, int(start + 1))\n",
    "        for i, (token_id, (start, end)) in enumerate(zip(token_ids, token_offsets))\n",
    "        if token_id == punctuation_mark_id\n",
    "        and (\n",
    "            token_offsets[i + 1][0] - token_offsets[i][1] > 0\n",
    "            or token_ids[i + 1] == sep_id\n",
    "        )\n",
    "    ]\n",
    "    chunks = [\n",
    "        input_text[x[1] : y[1]]\n",
    "        for x, y in zip([(1, 0)] + chunk_positions[:-1], chunk_positions)\n",
    "    ]\n",
    "    span_annotations = [\n",
    "        (x[0], y[0]) for (x, y) in zip([(1, 0)] + chunk_positions[:-1], chunk_positions)\n",
    "    ]\n",
    "    return chunks, span_annotations\n",
    " \n",
    "  \n",
    "def late_chunking(\n",
    "    model_output: 'BatchEncoding', span_annotation: list, max_length=None\n",
    "):\n",
    "    token_embeddings = model_output[0]\n",
    "    outputs = []\n",
    "    for embeddings, annotations in zip(token_embeddings, span_annotation):\n",
    "        if (\n",
    "            max_length is not None\n",
    "        ):  # remove annotations which go bejond the max-length of the model\n",
    "            annotations = [\n",
    "                (start, min(end, max_length - 1))\n",
    "                for (start, end) in annotations\n",
    "                if start < (max_length - 1)\n",
    "            ]\n",
    "        pooled_embeddings = [\n",
    "            embeddings[start:end].sum(dim=0) / (end - start)\n",
    "            for start, end in annotations\n",
    "            if (end - start) >= 1\n",
    "        ]\n",
    "        pooled_embeddings = [\n",
    "            embedding.detach().cpu().numpy() for embedding in pooled_embeddings\n",
    "        ]\n",
    "        outputs.append(pooled_embeddings)\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d293deb9-a4b6-471f-b50e-f0799dc71b82",
   "metadata": {},
   "source": [
    "### Import into Weaviate\n",
    "\n",
    "现在让我们使用视频描述数据集。我们稍后将使用late chunking/chunking查询此文本。\n",
    "此处我们使用分批次导入的方式，对每条数据的描述文本上下文embedding，然后将其导入 \n",
    "\n",
    "“OpenVidLateContext_jina_v2_zh”的 Weaviate 集合。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ea5fe-2f80-43fc-b8b4-ab7075d94f2e",
   "metadata": {},
   "source": [
    "现在，从 Huggingface 加载 jinaai/jina-embeddings-v2-base-zh 模型。 这个模型支持中英双语的文本向量模型，\n",
    "这对于后期分块很重要，因为我们希望对大型文档进行编码，然后再将它们分开。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e89fc7a2-0fbb-4cf5-b150-b364882c677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import transformers\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('/mnt/ceph/develop/jiawei/model_checkpoint/jina-embeddings-v2-base-zh', trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained('/mnt/ceph/develop/jiawei/model_checkpoint/jina-embeddings-v2-base-zh', trust_remote_code=True).to(device='cuda:0') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2f5b9a-a98b-4874-8e23-924b1e41cb1f",
   "metadata": {},
   "source": [
    "我们调用我们之前定义的函数：这里将每行对应一个上下文，我们希望对embedding后的token带有整体的信息，这里使用mark_text为`.`分割\n",
    "后，以获得块的起点和终点。\n",
    "然后嵌入整个文档。然后执行late chunking步骤 - 对与每个块相对应的所有标记嵌入取平均值（基于块的起点/终点）\n",
    "这些形成我们的块embedding。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5814ee18-a4b3-4745-bb0a-25aca55c668a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON streaming, to avoid running out of memory on large files...\n",
      "Processing chunk 1...\n",
      "Processing chunk 2...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer\n",
    "# Settings for displaying the import progress\n",
    "counter = 0\n",
    "interval = 200  # print progress every this many records; should be bigger than the batch_size\n",
    "collection = client.collections.get(\"OpenVidLateContext_jina_v2_zh\")\n",
    "\n",
    "print(\"JSON streaming, to avoid running out of memory on large files...\")\n",
    "  \n",
    "\n",
    "# 分块读取 CSV 文件\n",
    "chunk_size = 10000   # 每次读取10000行\n",
    "for idx, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size)):\n",
    "    print(f\"Processing chunk {idx + 1}...\")\n",
    "    for _, row in chunk.iterrows():\n",
    "        if idx<1:\n",
    "            continue\n",
    "        # 读取每一行的视频信息和标题等\n",
    "        video_filename = row['video']\n",
    "        caption = row['caption']\n",
    "        chunks, span_annotations = chunk_by_sentences(caption, tokenizer) \n",
    "        inputs = tokenizer(caption, return_tensors='pt').to(device='cuda:0')\n",
    "        model_output = model(**inputs)\n",
    "        chunk_embeddings = late_chunking(model_output, [span_annotations])[0] \n",
    "    \n",
    "        # add data with manual embeddings\n",
    "        data = []\n",
    "        for i in range(len(chunks)):\n",
    "            data.append(wvc.data.DataObject(\n",
    "          \n",
    "                    properties = {\n",
    "                        \"Video\": video_filename,\n",
    "                        \"Caption\": caption,\n",
    "                        \"content\": chunks[i]\n",
    "                    },\n",
    "                    vector = chunk_embeddings[i].tolist()\n",
    "            )\n",
    "        )\n",
    "        # 向量数据库插入数据\n",
    "        collection.data.insert_many(data);\n",
    "   \n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        # 每处理200条数据输出一次进度\n",
    "        if counter % interval == 0:\n",
    "            print(f\"Imported {counter} records...\")\n",
    "            \n",
    "# 完成后输出总进度\n",
    "print(f\"Finished importing {counter} records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58b501aa-c16f-434d-a117-a2dc5d55cd3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_ShardStatus(name='WAjUMOUHNYlr', status='READY', vector_queue_size=0)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "collection_shards = collection.config.get_shards()\n",
    "print(collection_shards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37ffdab0-8133-407b-a35f-ce0bf352046b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000094e9-73ac-49a2-b01c-0e61ded89d0d {'content': ' The style of the video is a close-up, real-time shot, focusing on the person and the computer setup.', 'caption': \"The video shows a person working on a computer setup. The person is wearing a black hoodie with an orange logo on the front. They are holding a red handle, possibly a tool, and are interacting with the computer setup. The setup includes various electronic components such as a motherboard, a power supply, and a fan. The person appears to be in the process of assembling or repairing the computer. The style of the video is a close-up, real-time shot, focusing on the person and the computer setup. The video captures the details of the electronic components and the person's actions, providing a clear view of the process.\", 'video': '-HO6Ys3PPIw_21_48to256.mp4'}\n"
     ]
    }
   ],
   "source": [
    "for item in collection.iterator():\n",
    "    print(item.uuid, item.properties)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebc9aad-80c6-4b86-9155-c7b8f29af1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:weaviate_client] *",
   "language": "python",
   "name": "conda-env-weaviate_client-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
